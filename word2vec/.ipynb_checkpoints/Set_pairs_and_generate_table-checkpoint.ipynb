{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# extract text and its position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.converter import TextConverter, HTMLConverter\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from io import StringIO\n",
    "\n",
    "\n",
    "def convert_pdf_to_txt(path1, path2, num = 0):\n",
    "    rsrcmgr = PDFResourceManager()\n",
    "    retstr = StringIO()\n",
    "    codec = 'utf-8'\n",
    "    laparams = LAParams()\n",
    "    device = HTMLConverter(rsrcmgr, retstr, codec=codec, laparams=laparams)\n",
    "    fp = open(path1, 'rb')\n",
    "    interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "    password = \"\"\n",
    "    maxpages = 0\n",
    "    caching = True\n",
    "    pagenos=set()\n",
    "\n",
    "    for i, page in enumerate(PDFPage.get_pages(fp, pagenos, maxpages=maxpages, password=password,caching=caching, check_extractable=True)):\n",
    "        if num > 0 and i > num:\n",
    "            break\n",
    "        interpreter.process_page(page)\n",
    "\n",
    "    text = retstr.getvalue()\n",
    "    file_name = 'page' + str(num)\n",
    "    f = open(path2+file_name, 'w')\n",
    "    f.write(text)\n",
    "    f.close()\n",
    "    #text = retstr.getvalue()\n",
    "    fp.close()\n",
    "    device.close()\n",
    "    retstr.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# set paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from Tkinter import *\n",
    "#import tkFileDialog\n",
    "from tkinter import *\n",
    "import tkinter.filedialog\n",
    "\n",
    "win = Tk()\n",
    "win.title('Select the PDF file')\n",
    "var = StringVar()\n",
    "\n",
    "w = Label(win, text=\"File Path:\")\n",
    "e = Entry(win, textvariable=var)\n",
    "#b = Button(win, text=\"Browse\",command=lambda:var.set(tkFileDialog.askopenfilename()))\n",
    "b = Button(win, text=\"Browse\",command=lambda:var.set(tkinter.filedialog.askopenfilename()))\n",
    "w.pack(side=LEFT)\n",
    "e.pack(side=LEFT)\n",
    "b.pack(side=LEFT)\n",
    "win.mainloop()\n",
    "\n",
    "path1 = var.get()\n",
    "\n",
    "win = Tk()\n",
    "win.title('Select the output file\\'s direnctory')\n",
    "var = StringVar()\n",
    "\n",
    "w = Label(win, text=\"File Path:\")\n",
    "e = Entry(win, textvariable=var)\n",
    "#b = Button(win, text=\"Browse\",command=lambda:var.set(tkFileDialog.askdirectory()))\n",
    "b = Button(win, text=\"Browse\",command=lambda:var.set(tkinter.filedialog.askdirectory()))\n",
    "w.pack(side=LEFT)\n",
    "e.pack(side=LEFT)\n",
    "b.pack(side=LEFT)\n",
    "win.mainloop()\n",
    "\n",
    "path2 = var.get()+'/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#path2 = 'C:/Users/zhongzhu/Documents/GitHub/work/temp/'\n",
    "#path1 = 'C:/Users/zhongzhu/Documents/GitHub/work/Seattle.pdf'\n",
    "#print(path1, path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "convert_pdf_to_txt(path1, path2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# record positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def record_pos(path, page=0, LINE_HEIGHT = 1, start_page=0, end_page=None):\n",
    "    f = open(path+'page'+str(page), 'r')\n",
    "    pages = f.read().split('#PAGE')\n",
    "    f.close()\n",
    "    \n",
    "    contents = {}\n",
    "    for page in pages[start_page: end_page]:\n",
    "        page_num = page[page.find('<<<')+3:page.find('>>>')]\n",
    "        page_, num = re.subn(r'<<<.*?>>>', '',page)\n",
    "    \n",
    "        boxes = page_.split('TEXT_BOX')\n",
    "\n",
    "        for content in boxes:\n",
    "            c = content.split(';')\n",
    "            if(c[0].find('left:') > 0): #if not empty\n",
    "                l = c[0][c[0].find('left:')+5:c[0].find('px')]\n",
    "                t = c[1][c[1].find('top:')+4:c[1].find('px')]\n",
    "                w = c[2][c[2].find('width:')+6:c[2].find('px')]\n",
    "                h = c[3][c[3].find('height:')+7:c[3].find('px')]\n",
    "\n",
    "                text = \"\".join(c[4:])\n",
    "                #contents[text.decode('utf-8')] = [(int(l), int(t), int(w), int(h))] #whole box\n",
    "                lines = text.split('\\n')\n",
    "\n",
    "                tempCount = 0\n",
    "                for line in lines:\n",
    "                    if re.search(r'[A-Za-z0-9,.?!]', line):\n",
    "                        if not line in contents:\n",
    "                            contents[line] = [(int(l), int(t)+tempCount, int(w), int(h), page_num)]\n",
    "                        else:\n",
    "                            contents[line].append((int(l), int(t)+tempCount, int(w), int(h), page_num))\n",
    "                    tempCount += LINE_HEIGHT ### default value 1\n",
    "    return contents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "contents = record_pos(path2)\n",
    "#for pos in contents:\n",
    "    #print(pos)\n",
    "    #print(contents[pos])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import Tkinter\n",
    "#import tkSimpleDialog\n",
    "import tkinter\n",
    "import tkinter.simpledialog\n",
    "\n",
    "#root = Tkinter.Tk()\n",
    "root = tkinter.Tk()\n",
    "root.title('select sample pages')\n",
    "var1 = tkinter.StringVar()\n",
    "var2 = tkinter.StringVar()\n",
    "#b1 = Button(root, text=\"Select start page\",command=lambda:var1.set(tkSimpleDialog.askinteger(\"Select start page\", \"enter page number\", parent = root)))\n",
    "#b2 = Button(root, text=\"Select end page\",command=lambda:var2.set(tkSimpleDialog.askinteger(\"Select end page\", \"enter page number\", parent = root)))\n",
    "b1 = tkinter.Button(root, text=\"Select start page\",command=lambda:var1.set(tkinter.simpledialog.askinteger(\"Select start page\", \"enter page number\", parent = root)))\n",
    "b2 = tkinter.Button(root, text=\"Select end page\",command=lambda:var2.set(tkinter.simpledialog.askinteger(\"Select end page\", \"enter page number\", parent = root)))\n",
    "b1.grid(column = 0, row = 0)\n",
    "b2.grid(column = 1, row = 0)\n",
    "#var = tkSimpleDialog.askstring(\"Select Pates\", \"enter your name\", parent = root)\n",
    "root.mainloop()\n",
    "start_page = var1.get()\n",
    "end_page = var2.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get the positions of some sample pages\n",
    "first_page_contents = record_pos(path2, start_page=int(start_page), end_page=int(end_page))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for i in first_page_contents:\n",
    "    #print(i)\n",
    "    #print(first_page_contents[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filted_contents = {}\n",
    "for text in contents:\n",
    "    if len(contents[text]) > 60:  ###set at beginning#####################\n",
    "        filted_contents[text] = contents[text]\n",
    "        #print(text + ' ' +str(len(filted_contents[text])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from Tkinter import *\n",
    "#import Tkinter as tk\n",
    "import tkinter as tk\n",
    "\n",
    "class Example(tk.Frame):\n",
    "     \n",
    "    def __init__(self, root, *args, **kwargs):\n",
    "        tk.Frame.__init__(self, root, *args, **kwargs)\n",
    "        self.root = root\n",
    "        self.vsb = tk.Scrollbar(self, orient=\"vertical\")\n",
    "        self.text = tk.Text(self, width=40, height=20, yscrollcommand=self.vsb.set)\n",
    "        self.vsb.config(command=self.text.yview)\n",
    "        self.vsb.pack(side=\"right\", fill=\"y\")\n",
    "        self.text.pack(side=\"left\", fill=\"both\", expand=True)\n",
    "        \n",
    "        self.temp_contents = {}\n",
    "\n",
    "        var = []\n",
    "        c = []\n",
    "        for i, cat in enumerate(sorted(filted_contents)):\n",
    "            c.append(cat)\n",
    "            v = tk.BooleanVar()\n",
    "            var.append(v)\n",
    "            cb = tk.Checkbutton(self, text=\"#%s\" % cat, variable=var[i])\n",
    "            self.text.window_create(\"end\", window=cb)\n",
    "            self.text.insert(\"end\", \"\\n\") # to force one checkbox per line\n",
    "                      \n",
    "        def var_states():\n",
    "            for i,v in enumerate(var):\n",
    "                if v.get():\n",
    "                    #print(c[i])\n",
    "                    self.temp_contents[c[i]] = filted_contents[c[i]]\n",
    "        tk.Button(root, text='Select', command=var_states).pack()\n",
    "        \n",
    "root = tk.Tk()\n",
    "root.title('selecte categories')\n",
    "win = Example(root)\n",
    "win.pack(side=\"top\", fill=\"both\", expand=True)\n",
    "root.mainloop()\n",
    "\n",
    "filted_contents = win.temp_contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# search neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "neighbors = {}\n",
    "    \n",
    "for line1, line2 in product(filted_contents, first_page_contents):\n",
    "    key = line1\n",
    "    value = line2\n",
    "    if not key in neighbors:\n",
    "        neighbors[key] = []\n",
    "    if(line1 != line2 and line1 in first_page_contents\n",
    "       and abs(int(first_page_contents[line1][0][0])-int(first_page_contents[line2][0][0]))<1000    ###set at beginning\n",
    "       and abs(int(first_page_contents[line1][0][1])-int(first_page_contents[line2][0][1]))<100): ###set at beginning\n",
    "        neighbors[key].append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for key in neighbors:\n",
    "    #print(key, neighbors[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import Tkinter as tk\n",
    "#import ttk\n",
    "import tkinter as tk\n",
    "import tkinter.ttk\n",
    "\n",
    "win = tk.Tk()\n",
    "win.title(\"Set Pairs\")   \n",
    "\n",
    "#ttk.Label(win, text=\"Select category:\").grid(column=0, row=0)   \n",
    "tkinter.ttk.Label(win, text=\"Select category:\").grid(column=0, row=0) \n",
    "#ttk.Label(win, text=\"content starts from\").grid(column=2, row=0) \n",
    "#ttk.Label(win, text=\"content ends before\").grid(column=3, row=0)     \n",
    "pos_or_area = StringVar()\n",
    "def select():  \n",
    "    if pos_or_area.get() == 'area':\n",
    "        ls = list(neighbors.keys())   \n",
    "        ls += ['#END']\n",
    "        dropdown2['values'] = ls\n",
    "    else:\n",
    "        ls = neighbors[category.get()]\n",
    "        dropdown2['values'] = ls\n",
    "    dropdown2.current()    \n",
    "\n",
    "R1 = tkinter.ttk.Radiobutton(win, text=\"find by position\", variable=pos_or_area, value='pos', command=select)\n",
    "R1.grid(column = 2, row = 0)\n",
    "R2 = tkinter.ttk.Radiobutton(win, text=\"find by area\", variable=pos_or_area, value='area', command=select)\n",
    "R2.grid(column = 3, row = 0)\n",
    "    \n",
    "pairs = {}\n",
    "def bind():   \n",
    "    #key = contents[category.get()]\n",
    "    #new_value = contents[content.get()]\n",
    "    key = category.get()\n",
    "    if not key in pairs:\n",
    "        pairs[key] = set([])\n",
    "    \n",
    "    if pos_or_area.get()=='pos':\n",
    "        a = first_page_contents[category.get()][0]\n",
    "        b = first_page_contents[content.get()][0]\n",
    "        c = (b[0]-a[0], b[1]-a[1], b[2]-a[2], b[3]-a[3], b[4], pos_or_area.get())\n",
    "        pairs[key].add(c)\n",
    "    else:\n",
    "        c = (content.get(), pos_or_area.get()) \n",
    "        pairs[key].add(c)\n",
    "        \n",
    "    dropdown2.current()\n",
    "    \n",
    "# creat a drop-down list\n",
    "category = tk.StringVar()\n",
    "dropdown1 = tkinter.ttk.Combobox(win, width=40, height=20, textvariable=category)\n",
    "dropdown1['values'] = list(neighbors.keys())   \n",
    "dropdown1.grid(column=0, row=1)      \n",
    "#dropdown1.current(0)     \n",
    "\n",
    "\n",
    "# create another drop-down list\n",
    "content = tk.StringVar()\n",
    "dropdown2 = tkinter.ttk.Combobox(win, width=40, textvariable=content)    \n",
    "dropdown2.grid(column=2, row=1)  \n",
    " \n",
    "\n",
    "# bind button\n",
    "action = tkinter.ttk.Button(win, text=\"Bind\", command=bind)\n",
    "action.grid(column=4, row=1) \n",
    "\n",
    "win.mainloop()      # window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#for i in pairs:\n",
    "    #print(i)\n",
    "    #print(type(pairs[i]))\n",
    "    #print((pairs[i]))\n",
    "    #for i in pairs[i]:\n",
    "        #print(len(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "page = 0\n",
    "f = open(path2+'page'+str(page), 'r')\n",
    "text = f.read()\n",
    "text, num = re.subn(r'TEXT_BOX.*?height:[\\d]+px;', '',text)\n",
    "f.close()\n",
    "\n",
    "reports = {}\n",
    "pages = text.split('#PAGE')\n",
    "for page in pages:\n",
    "    if(len(page) == 0):\n",
    "        continue\n",
    "    page_num = page[page.find('<<<')+3:page.find('>>>')]\n",
    "    page_, num = re.subn(r'<<<.*?>>>', '',page)\n",
    "    reports[int(page_num)] = page_\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from io import StringIO\n",
    "\n",
    "def pdf2txt(path):\n",
    "    rsrcmgr = PDFResourceManager()\n",
    "    retstr = StringIO()\n",
    "    codec = 'utf-8'\n",
    "    laparams = LAParams()\n",
    "    device = TextConverter(rsrcmgr, retstr, codec=codec, laparams=laparams)\n",
    "    fp = open(path, 'rb')\n",
    "    interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "    password = \"\"\n",
    "    maxpages = 0\n",
    "    caching = True\n",
    "    pagenos=set()\n",
    "\n",
    "    for page in PDFPage.get_pages(fp, pagenos, maxpages=maxpages, password=password,caching=caching, check_extractable=True):\n",
    "        interpreter.process_page(page)\n",
    "\n",
    "    text = retstr.getvalue()\n",
    "\n",
    "    fp.close()\n",
    "    device.close()\n",
    "    retstr.close()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "text = pdf2txt(path1)\n",
    "\n",
    "reports = {}\n",
    "pages = text.split('#PAGE')\n",
    "for page in pages:\n",
    "    if(len(page) == 0):\n",
    "        continue\n",
    "    page_num = page[page.find('<<<')+3:page.find('>>>')]\n",
    "    page_, num = re.subn(r'<<<.*?>>>', '',page)\n",
    "    try:\n",
    "        reports[int(page_num)] = page_\n",
    "    except:\n",
    "        print(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_content_by_area(text, start, end, head='CONTRACT NUMBER'): #####\n",
    "    #p = re.compile(r'{%s}.*{%s}' % (start, end))\n",
    "    start = start.lstrip()\n",
    "    end = end.lstrip()\n",
    "    content= []\n",
    "    flag = False\n",
    "    #for page_num, page in sorted(reports.iteritems()):\n",
    "    for page_num, page in sorted(reports.items()):\n",
    "        search = []\n",
    "        if flag:\n",
    "            flag = False\n",
    "            search = re.findall('%s.*?%s' % (head, end), page, re.DOTALL)\n",
    "        elif end != 'END' and start in page and end in page:\n",
    "            search = re.findall('%s.*?%s' % (start, end), page, re.DOTALL)\n",
    "        else:\n",
    "            search = re.findall('%s.*' % start, page, re.DOTALL)\n",
    "            flag = True\n",
    "        for i in search:\n",
    "            i = i.replace(start, '')\n",
    "            i = i.replace(end, '')\n",
    "            i = i.replace('\\n\\n', ' ')\n",
    "            #content.append('#PAGE_'+str(page_num)+' '+i)\n",
    "            content.append(' ' + i)\n",
    "    #print(content)\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = {}\n",
    "for cat in pairs:\n",
    "    for c in pairs[cat]:\n",
    "        if c[-1] == 'area':\n",
    "            content = find_content_by_area(text, cat, c[0], )\n",
    "            data[cat] = content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(' EQUIPMENT HOURS', 'area')}\n"
     ]
    }
   ],
   "source": [
    "def find_content_by_pos(content_map, content_pos):\n",
    "    content = ''\n",
    "    for c in content_map:\n",
    "        m = 1 #### maximal error allowed#########################\n",
    "        for pos in content_map[c]:\n",
    "            error = abs(content_pos[0]-pos[0]) + abs(content_pos[1]-pos[1])\n",
    "            #print error\n",
    "            if error < m:\n",
    "                content += '#PAGE_'+pos[-1]+' '+c\n",
    "    #print(m)\n",
    "    return content\n",
    "    \n",
    "#data = {}\n",
    "content_map = record_pos(path2, 0)\n",
    "for cat in pairs:\n",
    "    print(pairs[cat])\n",
    "    #if cat in content_map:  #unnecessary??\n",
    "    for pos in content_map[cat]:\n",
    "        content = ''\n",
    "        for shift in pairs[cat]:\n",
    "            if shift[-1] == 'pos':\n",
    "                content_pos = (pos[0]+shift[0], pos[1]+shift[1], pos[2]+shift[2], pos[3]+shift[3])\n",
    "                content += find_content_by_pos(content_map, content_pos)\n",
    "        if len(content) != 0:\n",
    "            if cat in data: #unnecessary??\n",
    "                data[cat].append(content)\n",
    "            else:\n",
    "                data[cat] = [content]\n",
    "           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# generate CSV table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#for i in data:\n",
    "    #print (i)\n",
    "    #for j in data[i]:\n",
    "        #print (j)\n",
    "#print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "f = open(path2+'result_py3.csv', 'w', newline = '')\n",
    "writer = csv.writer(f)\n",
    "\n",
    "for i, cat in enumerate(data):\n",
    "    #if i >50:\n",
    "        #break\n",
    "    writer.writerow([cat] + data[cat])\n",
    "    #print(i) \n",
    "    #print(cat)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# new "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'ehabs_stop_words.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-0481847ab130>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mehab_stop_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr\"ehabs_stop_words.txt\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mehab_stop_words\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'ehabs_stop_words.txt'"
     ]
    }
   ],
   "source": [
    "ehab_stop_words = []\n",
    "\n",
    "for word in open(r\"ehabs_stop_words.txt\",'r'):\n",
    "    ehab_stop_words.append(word.strip())\n",
    "\n",
    "from sklearn.feature_extraction import text \n",
    "\n",
    "my_stop_words = text.ENGLISH_STOP_WORDS.union(ehab_stop_words) # union the ehab's stop words and the stop words in the pachage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([' LABOR HOURS'])\n"
     ]
    }
   ],
   "source": [
    "print(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "311\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-505bbd34e4d0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[0mselected_feature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m     \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mword_vectors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtopn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mselected_feature\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'features' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from nltk import word_tokenize,sent_tokenize\n",
    "\n",
    "#raw_data = pd.read_csv(\"out.csv\", header=0, sep=None, usecols=['description'], engine='python')\n",
    "def review_to_wordlist(raw_sentence, join=0):\n",
    "    review_text = re.sub(\"[^a-zA-Z]\", \" \", raw_sentence)\n",
    "    words = review_text.lower().split()\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    meaningful_words = [w for w in words if not w in stops]\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = [lemmatizer.lemmatize(w) for w in words]\n",
    "    if join:\n",
    "        return (\" \".join(words))\n",
    "    else:\n",
    "        return words\n",
    "\n",
    "def review_to_sentences(review):\n",
    "    raw_sentences = sent_tokenize(review.strip())\n",
    "    sentences = []\n",
    "    for raw_sentence in raw_sentences:\n",
    "        if len(raw_sentence) > 0:\n",
    "            sentences.append(review_to_wordlist(raw_sentence))\n",
    "    return sentences\n",
    "\n",
    "sentences = []\n",
    "\n",
    "for review in data[' LABOR HOURS']:\n",
    "    sentences += review_to_sentences(review)\n",
    "\n",
    "#print(sentences)\n",
    "\n",
    "#print (len(sentences))\n",
    "#print (sentences[0])\n",
    "model = Word2Vec(sentences,min_count=1,sg=1)\n",
    "print(len(model.wv.vocab.keys()))\n",
    "#model.build_vocab(features)\n",
    "#print(len(model['medical']))\n",
    "\n",
    "#word_vectors = model.wv\n",
    "#word_vectors.save('similar_stopwords')\n",
    "\n",
    "#word_vectors = KeyedVectors.load('similar')\n",
    "\n",
    "#features = ['contest', 'drug', 'horror','medical', 'treatment']\n",
    "\n",
    "selected_feature = []\n",
    "\n",
    "for i in features:\n",
    "    a = word_vectors.wv.most_similar(i, topn=2)\n",
    "    selected_feature += [j[0] for j in a]\n",
    "    print(a)\n",
    "\n",
    "print(selected_feature)\n",
    "clean_data = []\n",
    "num_data = raw_data[\"description\"].size\n",
    "for i in range(0, num_data):\n",
    "    clean_data.append(review_to_wordlist(raw_data[\"description\"][i], join=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
