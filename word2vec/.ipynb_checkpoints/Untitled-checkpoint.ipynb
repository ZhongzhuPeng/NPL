{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning, module='gensim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ">>> from gensim import corpora, models, similarities\n",
    ">>>\n",
    ">>> corpus = ['the quick brown fox jumps over the lazy dog'.split(), 'how many roads must a man walk down'.split(), \n",
    "              'before they call him a man', 'like a rolling stone'.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> w2v = models.word2vec.Word2Vec(corpus,min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -2.20252457e-03,  -2.93123443e-03,  -4.24732175e-03,\n",
       "         1.13977690e-03,   2.09017028e-03,   3.38892289e-03,\n",
       "         2.00991592e-04,  -2.84928898e-03,   5.65921597e-04,\n",
       "         6.33544754e-04,  -1.43880243e-04,  -4.33103507e-03,\n",
       "        -1.37745205e-03,   7.02146208e-04,   3.26461392e-03,\n",
       "        -3.51875275e-03,  -2.29423447e-03,  -4.24831873e-03,\n",
       "        -4.75346204e-03,  -3.72820045e-03,  -4.12788679e-04,\n",
       "         3.40206642e-03,   4.46936302e-03,   2.74300762e-03,\n",
       "         1.52731757e-03,  -3.38380830e-03,   4.44702199e-03,\n",
       "        -1.10007334e-03,   4.83500678e-03,  -2.13171868e-03,\n",
       "        -2.90669338e-03,   8.05522213e-05,  -4.17428743e-03,\n",
       "        -2.29578698e-03,   2.33151554e-03,  -1.17941247e-03,\n",
       "        -4.52139741e-03,   6.31354284e-04,   4.43097064e-03,\n",
       "         7.71481660e-04,  -4.31542867e-04,   3.14660207e-03,\n",
       "         7.41905009e-04,   3.11477669e-03,   4.74632997e-03,\n",
       "        -4.85692499e-03,   1.51271187e-03,   4.05752379e-03,\n",
       "        -4.97202575e-03,  -5.32341131e-04,  -1.33841153e-04,\n",
       "        -1.94186359e-04,  -2.36664573e-03,   2.52695451e-03,\n",
       "        -2.06505787e-03,  -4.90465481e-03,  -3.49787483e-03,\n",
       "         1.09133509e-03,  -4.36499156e-03,  -3.80081078e-03,\n",
       "         1.91157073e-04,   5.24439150e-04,   2.80767184e-04,\n",
       "        -1.58724899e-03,  -2.17248057e-03,  -9.38303652e-04,\n",
       "        -3.77206830e-03,  -7.29850086e-04,  -3.18208290e-03,\n",
       "        -1.41305872e-03,   4.24743071e-03,   2.84765824e-03,\n",
       "        -2.14842893e-03,   2.32317229e-03,   4.06374782e-03,\n",
       "         3.96406604e-03,   3.94117506e-03,   1.04564871e-03,\n",
       "        -4.14143130e-03,  -4.60682990e-04,  -3.00484663e-03,\n",
       "        -1.13332679e-03,   3.51525471e-03,   1.89270498e-03,\n",
       "         1.55938882e-03,  -7.43071607e-04,   2.77566840e-03,\n",
       "        -4.89249767e-04,  -3.47701577e-03,  -2.54559843e-03,\n",
       "         7.05704442e-04,   3.52648948e-03,   1.11534435e-03,\n",
       "        -2.09494168e-03,  -1.97479781e-03,  -4.77502728e-03,\n",
       "         1.98887102e-03,  -6.14463410e-04,   1.36274565e-03,\n",
       "         2.32327590e-03], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.wv['how']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"word 'woman' not in vocabulary\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-d0f83888a66a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mw2v\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimilarity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'woman'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'man'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\zhongzhu\\Anaconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36msimilarity\u001b[1;34m(self, w1, w2)\u001b[0m\n\u001b[0;32m    607\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    608\u001b[0m         \"\"\"\n\u001b[1;32m--> 609\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munitvec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mw1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmatutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munitvec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mw2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    610\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    611\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mn_similarity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mws1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mws2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\zhongzhu\\Anaconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, words)\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m             \u001b[1;31m# allow calls like trained_model['office'], as a shorthand for trained_model[['office']]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 589\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    590\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    591\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\zhongzhu\\Anaconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36mword_vec\u001b[1;34m(self, word, use_norm)\u001b[0m\n\u001b[0;32m    286\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msyn0\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 288\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"word '%s' not in vocabulary\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    289\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    290\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmost_similar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpositive\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnegative\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtopn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrestrict_vocab\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"word 'woman' not in vocabulary\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "\n",
    "raw_data = pd.read_csv(\"out.csv\", header=0, sep=None, usecols=['description'], engine='python')\n",
    "def review_to_wordlist(raw_sentence, join=0):\n",
    "    review_text = re.sub(\"[^a-zA-Z0-9]\", \" \", raw_sentence)\n",
    "    words = review_text.lower().split()\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    meaningful_words = [w for w in words if not w in stops]\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = [lemmatizer.lemmatize(w) for w in words]\n",
    "    if join:\n",
    "        return (\" \".join(words))\n",
    "    else:\n",
    "        return words\n",
    "\n",
    "\n",
    "def review_to_sentences(review):\n",
    "    raw_sentences = sent_tokenize(review.strip())\n",
    "    sentences = []\n",
    "    for raw_sentence in raw_sentences:\n",
    "        if len(raw_sentence) > 0:\n",
    "            sentences.append(review_to_wordlist(raw_sentence))\n",
    "    return sentences\n",
    "\n",
    "sentences = []\n",
    "\n",
    "for review in raw_data[\"description\"]:\n",
    "    sentences += review_to_sentences(review)\n",
    "\n",
    "print(sentences)\n",
    "\n",
    "#print (len(sentences))\n",
    "#print (sentences[0])\n",
    "model = Word2Vec(sentences, size=23200,min_count=1)\n",
    "#print(model.wv.syn0.shape)\n",
    "#model.build_vocab(features)\n",
    "#print(len(model['medical']))\n",
    "\n",
    "#word_vectors = model.wv\n",
    "#word_vectors.save('similar_stopwords')\n",
    "\n",
    "word_vectors = KeyedVectors.load('similar')\n",
    "\n",
    "features = ['contest', 'drug', 'horror','medical', 'treatment']\n",
    "\n",
    "\n",
    "selected_feature = []\n",
    "\n",
    "for i in features:\n",
    "    a = word_vectors.wv.most_similar(i, topn=2)\n",
    "    selected_feature += [i[0] for i in a]\n",
    "    print(a)\n",
    "\n",
    "print(selected_feature)\n",
    "clean_data = []\n",
    "num_data = raw_data[\"description\"].size\n",
    "for i in range(0, num_data):\n",
    "    clean_data.append(review_to_wordlist(raw_data[\"description\"][i], join=1))\n",
    "\n",
    "\n",
    "#count_vectorizer = CountVectorizer(binary=True)\n",
    "#feature_vec = count_vectorizer.fit(selected_feature)\n",
    "#term_freq_matrix = count_vectorizer.transform(clean_data)\n",
    "\n",
    "#count_vectorizer.get_feature_names()\n",
    "\n",
    "#out = pd.DataFrame(data=term_freq_matrix.toarray(), columns=count_vectorizer.get_feature_names())\n",
    "\n",
    "#out.to_csv(\"similarity.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
